{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pennsylvania Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "**Task:** Create a file with the Pennsylvania Outpatient Fee Schedules information where the data is in a standardized format that can be easily used in a tool that compares fee schedules across states.  \n",
    "**Link:** https://www.humanservices.state.pa.us/outpatientfeeschedule  \n",
    "**Project:** 50887 Medicaid Access  \n",
    "**Programmer:** Emma Pendl-Robinson  \n",
    "**Last update:** May 28, 2020   \n",
    "\n",
    "**Steps of Scraper**\n",
    "\n",
    "The script is broken down into functions that are put together in `main` \n",
    "1. `main`  \n",
    "    A.\tTakes the last of wanted providers (i.e. provider texts)  \n",
    "    B.\tGives `nav_provider` the providers one at a time  \n",
    "    C.\tCombines all provider data (i.e. `data_total`) and all row check data (i.e. `row_total`)    \n",
    "    D.\tWrites out all provide data (using ` write_out_data`)  \n",
    "  \n",
    "2.\t`nav_provider`  \n",
    "    A.\tOpens chrome  \n",
    "    B.\tOpens the Pennsylvania Outpatient and Dental Fee Schedule Database user agreement page  \n",
    "    C.\tClicks “I Accept” on the user agreement page  \n",
    "    D.\tFinds the “Select Provider” drop down menu  \n",
    "    E.\tSelects the provider given by `main`  \n",
    "    F.\tClicks “Get Fee Schedule Details”  \n",
    "    G.\tChanges “show entries” at the top left of the graph to “100”  \n",
    "    H.\tReturns the provider results page (i.e. `driver`) to `main`\n",
    "3.\t` get_provider_results`  \n",
    "    A.\tTakes results page from `main`  \n",
    "    B.\tFinds and takes the result message text (i.e. “Your search yielded ___ results.”)  \n",
    "    C.\tGives the number of results (i.e. rows) to `get_page_num`  \n",
    "    D.\tTakes the number of pages from ` get_page_num`  \n",
    "    E.\tStores the results text and page count as a check (i.e. `rows_one_provider`)  \n",
    "    F.\tGives the number of pages and the provider results page (i.e. the `driver`) to `get_provider_data`  \n",
    "4.\t`get_page_num` \n",
    "    A.\tTakes the results page (i.e. the `driver`) from `get_provider_results`  \n",
    "    B.\tAssumes each page shows 100 results  \n",
    "    C.\tCalculates the number of pages bases on the results  \n",
    "    D.\tGives the number of pages to `get_provider_results`  \n",
    "5.\t`get_provider_data`  \n",
    "    A.\tTakes the number of pages and the provider results page (i.e. the `driver`) from `get_provider_results`  \n",
    "    B.\tGives `get_provider_data` one page number at a time and the provider results page (i.e. the `driver`)  \n",
    "    C.\tTakes the complete provider data (i.e. `data_one_provider`) from ` get_data_provider`  \n",
    "    D.\tReturns the results checks (i.e. `rows_one_provider`) and the complete provider data (i.e. `data_one_provider`) to `main`  \n",
    "6.\t`scrape_one_page`  \n",
    "    A.\tTakes the number of pages and the provider results page (i.e. the `driver`) from `get_data_provider`  \n",
    "    B.\tFinds the page number on the provider results page (i.e. the `driver`)  \n",
    "    C.\tClicks on the page number  \n",
    "    D.\tScrapes all the table rows and columns  \n",
    "    E.\tReturns the data (i.e. `new_data`) to `get_data_provider`  \n",
    "7.\t` write_out_data`  \n",
    "    A.\tTakes all provider data (i.e. `data_total`) from `main`  \n",
    "    B.\tConvert the provider data from list format to a data frame (i.e. `raw_df`)  \n",
    "    C.\tWrite out all provider data as data frame  (i.e. `raw_df`)\n",
    "    D.\tSelects the columns from provider a data frame we need from all data (`raw_df`)\n",
    "    E.\tChanges the column names to match the formatting of the other state data  (i.e. `clean_df`)\n",
    "    F.\tAdds column for state name  (i.e. `clean_df`)\n",
    "    G.\tWrites out clean data (i.e. `clean_df`)\n",
    "\n",
    "**Providers to Pull**:  \n",
    "- 05 - Home Health  \n",
    "- 09 - Certified Registered Nurse Practitioner  \n",
    "- 11 - Mental Health / Substance Abuse  \n",
    "- 27 - Dentist  \n",
    "- 31 - Physician (all of them - broken up by procedure code in database)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package             Version\n",
      "------------------- --------\n",
      "argon2-cffi         20.1.0\n",
      "async-generator     1.10\n",
      "attrs               21.2.0\n",
      "backcall            0.2.0\n",
      "bleach              3.3.1\n",
      "cffi                1.14.6\n",
      "colorama            0.4.4\n",
      "decorator           5.0.9\n",
      "defusedxml          0.7.1\n",
      "entrypoints         0.3\n",
      "importlib-metadata  4.6.1\n",
      "ipykernel           5.5.5\n",
      "ipython             7.16.1\n",
      "ipython-genutils    0.2.0\n",
      "ipywidgets          7.6.3\n",
      "jedi                0.18.0\n",
      "Jinja2              3.0.1\n",
      "jsonschema          3.2.0\n",
      "jupyter             1.0.0\n",
      "jupyter-client      6.2.0\n",
      "jupyter-console     6.4.0\n",
      "jupyter-core        4.7.1\n",
      "jupyterlab-pygments 0.1.2\n",
      "jupyterlab-widgets  1.0.0\n",
      "MarkupSafe          2.0.1\n",
      "mistune             0.8.4\n",
      "nbclient            0.5.3\n",
      "nbconvert           6.0.7\n",
      "nbformat            5.1.3\n",
      "nest-asyncio        1.5.1\n",
      "notebook            6.4.0\n",
      "packaging           21.0\n",
      "pandocfilters       1.4.3\n",
      "parso               0.8.2\n",
      "pickleshare         0.7.5\n",
      "pip                 21.2.1\n",
      "prometheus-client   0.11.0\n",
      "prompt-toolkit      3.0.19\n",
      "pycparser           2.20\n",
      "Pygments            2.9.0\n",
      "pyparsing           2.4.7\n",
      "pyrsistent          0.18.0\n",
      "python-dateutil     2.8.2\n",
      "pywin32             301\n",
      "pywinpty            1.1.3\n",
      "pyzmq               22.1.0\n",
      "qtconsole           5.1.1\n",
      "QtPy                1.9.0\n",
      "selenium            3.141.0\n",
      "Send2Trash          1.7.1\n",
      "setuptools          57.4.0\n",
      "six                 1.16.0\n",
      "terminado           0.10.1\n",
      "testpath            0.5.0\n",
      "tornado             6.1\n",
      "traitlets           4.3.3\n",
      "typing-extensions   3.10.0.0\n",
      "urllib3             1.26.6\n",
      "wcwidth             0.2.5\n",
      "webencodings        0.5.1\n",
      "wheel               0.36.2\n",
      "widgetsnbextension  3.5.1\n",
      "zipp                3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('C:\\\\fxing\\\\15_DS_specialization\\\\topic4_NLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "import math\n",
    "import numpy as np\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.support.ui import Select\n",
    "import time\n",
    "# import git\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find current time\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "# find current commit hash\n",
    "repo = git.Repo(search_parent_directories=True)\n",
    "commit_hash = repo.head.object.hexsha[0:7]\n",
    "\n",
    "# providers list\n",
    "providers_want = [5, 9, 11, 27, 31]\n",
    "\n",
    "def create_path(last_part_path, file_type = \".csv\"): \n",
    "    ''' \n",
    "    take last part of path and provide path with identifying information\n",
    "    '''\n",
    "    path = ROOT + last_part_path + \"_\" + timestr + \"_\"+ commit_hash + file_type\n",
    "    \n",
    "    return path\n",
    "\n",
    "# file paths\n",
    "ROOT = \"N:/Project/50887_MedicaidAccess/DC1/Task 5/Payment Rate Comparison Tool/data/\"\n",
    "\n",
    "DICT_OUT_PATH = create_path(\"raw/pa_scraper/pa_fee_dict\", \".txt\")\n",
    "RAW_DF_OUT_PATH = create_path(\"raw/pa_scraper/pa_fee_df\")\n",
    "LOG_OUT_PATH = create_path(\"interim/pa_scraper/checks/app\", \".log\")\n",
    "CLEAN_DF_OUT_PATH = create_path(\"interim/pa_scraper/cleaned_outputs/pa_fee_clean\")\n",
    "\n",
    "URL = \"https://www.humanservices.state.pa.us/outpatientfeeschedule\"\n",
    "DRIVER_PATH =  \"C:/Users/ependl-robinson/Projects/Extranious/seleniumdrivers/chromedriver_v83.exe\"\n",
    "\n",
    "\n",
    "# configure logging\n",
    "logging.basicConfig(filename= LOG_OUT_PATH, filemode='w',  \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    datefmt='%d-%b-%y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "\n",
    "def get_provider_list (driver_path, url_path):\n",
    "    '''find the list of possible provider values'''\n",
    "    driver = webdriver.Chrome(driver_path)\n",
    "    driver.get(url_path)\n",
    "    driver.find_element_by_id('btnSubmit').click()\n",
    "\n",
    "    # switch to opened window\n",
    "    window_providers = driver.window_handles[0]\n",
    "    driver.switch_to.window(window_providers)\n",
    "    \n",
    "    for provider in driver.find_elements_by_xpath('//*[@id=\"Provider\"]'):\n",
    "        provider_list = [item.text for item in provider.find_elements_by_xpath(\".//*[self::option]\")]\n",
    "    provider_list = [x for x in provider_list if re.match(r'[0-9]', x)]\n",
    "    driver.quit()\n",
    "\n",
    "    return (provider_list)\n",
    "\n",
    "\n",
    "def select_providers (providers, value_list): \n",
    "    '''\n",
    "    providers -- providers researchers want\n",
    "    value_list -- list from select provider drop down menu \n",
    "    \n",
    "    '''\n",
    "    select_total = []\n",
    "    for provider in providers:\n",
    "        # convert to string at leading zero for single digets\n",
    "        provider = str(provider)\n",
    "        if len(provider) == 1:\n",
    "            provider_regex = \"0\" + provider + \"[^0-9]\"\n",
    "        else:\n",
    "            provider_regex = provider + \"[^0-9]\"\n",
    "            \n",
    "        code_patern = re.compile(provider_regex)\n",
    "        # find strings\n",
    "        select = [s for s in value_list if code_patern.match(s)]\n",
    "        select_total= select_total + select\n",
    "        \n",
    "    return(select_total)\n",
    "\n",
    "def scrape_page(page, driver):\n",
    "    '''navigate to and select specified page returns rows of table on page\n",
    "    \n",
    "    Keyword arguments:\n",
    "    page -- the imput page number (as string)\n",
    "    driver -- chrome driver\n",
    "    '''\n",
    "    # page_button -- the button element coresponding to 'page' then click button   \n",
    "    page_button = driver.find_element_by_xpath(\"//a[@aria-controls= 'tblResult'][text()=\" + str(page) + \"]\")\n",
    "    driver.execute_script(\"arguments[0].click();\", page_button)\n",
    "    \n",
    "    # row_count -- start of the provider row count for the page\n",
    "    # e.g. for page 3 row 20, row_count = 220\n",
    "    page_dict = dict()\n",
    "    row_count = (page-1)*100\n",
    "    \n",
    "    # get col names list\n",
    "    for thead in driver.find_elements_by_xpath('//*[@id=\"tblResult\"]/thead'):\n",
    "        col_list = [item.text for item in thead.find_elements_by_xpath(\".//*[self::th]\")]\n",
    "    \n",
    "    # row -- the rows of the table on page\n",
    "    # get row values\n",
    "    for row in driver.find_elements_by_xpath('//*[@id=\"tblResult\"]/tbody/tr'):\n",
    "        row_list = [item.text for item in row.find_elements_by_xpath(\".//*[self::td]\")]\n",
    "        \n",
    "        # combine lists to make dic\n",
    "        # should write assertion to make sure lists can be zipped\n",
    "        row_dict = {k:v for k, v in zip(col_list, row_list)}\n",
    "        page_dict[row_count] = row_dict\n",
    "        row_count = row_count + 1\n",
    "        \n",
    "    return(page_dict)\n",
    "\n",
    "\n",
    "def get_provider_data(pages, driver):\n",
    "    '''returns all data for the 1 given provider (data_one_provider)\n",
    "    \n",
    "    Keyword arguments:\n",
    "    pages -- total number of pages for proivder, integers inclusive of last page\n",
    "    driver -- chrome driver\n",
    "    '''\n",
    "    # one_provider_dict -- all data scraped for this provider as dict\n",
    "    provider_dict = dict()\n",
    "    \n",
    "    for page in range(1, pages + 1):\n",
    "        page_dict = scrape_page(page, driver)\n",
    "        provider_dict.update(page_dict)\n",
    "    \n",
    "    return(provider_dict)\n",
    "\n",
    "def get_page_num(row_count_int):\n",
    "    '''returns total number of pages'''\n",
    "    temp = row_count_int/100 \n",
    "    pages = math.ceil(temp)\n",
    "    \n",
    "    return(pages)\n",
    "\n",
    "def get_provider_results(provider_text, driver):\n",
    "    ''' return all data for provider and total row count\n",
    "    \n",
    "    Keyword arguments:\n",
    "    provider_text -- name of provider (as string)\n",
    "    driver -- chrome driver\n",
    "    '''  \n",
    "    # results_text -- string containing number of results i.e. rows\n",
    "    # row_count_list -- count of rows of provider (as list)\n",
    "    # row_count_int -- count of rows of provider (as interger)\n",
    "    \n",
    "    results_text = driver.find_element_by_id('ResultsMessage').text\n",
    "    row_count_list = re.findall(r'\\d+', results_text)\n",
    "    row_count_int = int(row_count_list[0])\n",
    "    \n",
    "    pages = get_page_num(row_count_int)\n",
    "    \n",
    "    # check_one_provider -- total numper of rows for providers\n",
    "    provider_dict = get_provider_data(pages, driver)\n",
    "    \n",
    "    provider_check = {'provider_text':provider_text, \n",
    "                      'results_text':results_text, \n",
    "                      'row_count':str(row_count_int), \n",
    "                      'num_pages':str(pages)}\n",
    "\n",
    "    # assert -- assertion to see that the number of keys in provider_dict matches number of expected number of rows   \n",
    "\n",
    "    try:\n",
    "        assert len(provider_dict) == row_count_int, \"number of values scraped does not match number of rows\"\n",
    "    except AssertionError:\n",
    "        logging.exception(\"number of values scraped does not match number of rows\")\n",
    "        raise\n",
    "    \n",
    "    logging.info('complete data scraped for ' + str(provider_text))\n",
    "    \n",
    "    return(provider_dict, provider_check)\n",
    "\n",
    "def nav_provider(provider_text, driver_path, url_path):\n",
    "    ''' takes provider name and brings to provider's fees\n",
    "    \n",
    "    Keyword arguments:\n",
    "    provider_text -- name of provider (as string)\n",
    "    '''\n",
    "    driver = webdriver.Chrome(driver_path)\n",
    "    driver.get(url_path)\n",
    "    driver.find_element_by_id('btnSubmit').click()\n",
    "\n",
    "    # switch to opened window\n",
    "    window_providers = driver.window_handles[0]\n",
    "    driver.switch_to.window(window_providers)\n",
    "    \n",
    "    proivder_menu = Select(driver.find_element_by_id('Provider'))\n",
    "    proivder_menu.select_by_visible_text(provider_text)\n",
    "\n",
    "    driver.find_element_by_id('btnFeesSearch').click()\n",
    "    \n",
    "    # switch to opened window\n",
    "    window_fees = driver.window_handles[0]\n",
    "    driver.switch_to.window(window_fees)\n",
    "\n",
    "    result_length_list = Select(driver.find_element_by_name('tblResult_length'))\n",
    "    result_length_list.select_by_value(\"100\")\n",
    "    \n",
    "    return(driver)\n",
    "        \n",
    "def write_out_data(provider_total_dict, dict_out_path, raw_df_out_path, clean_df_out_path):\n",
    "    ''' save out raw data and clean data\n",
    "    \n",
    "    Keyword arguments:\n",
    "    data_total -- all data scraped from all providers (as list)\n",
    "    '''\n",
    "    # creating dictionaries of column names\n",
    "    col_names_dict={\"Prov Type\": \"fn\",\n",
    "               \"Prov Spclty Code\": None,\n",
    "               \"Proc Code\": \"CPT Code\", \n",
    "               \"Modifier\": \"Modifier\", \n",
    "               \"Proc Price Amt\" : \"Fee\",\n",
    "               \"Place of Service\": \"place_of_service\",\n",
    "               \"Details\": None\n",
    "              }\n",
    "\n",
    "    col_names_dict_filter = {k: v for k, v in col_names_dict.items() if v is not None}\n",
    "    \n",
    "    # write out dict    \n",
    "    with open(dict_out_path, 'w') as f:\n",
    "        print(provider_total_dict, file=f)\n",
    "    \n",
    "    # raw_df -- all data from all providers (as dataframe)\n",
    "    raw_df = pd.concat({k: pd.DataFrame(v).T for k, v in provider_total_dict.items()}, axis=0)\n",
    "    \n",
    "    raw_df.to_csv(raw_df_out_path, index=False)\n",
    "    logging.info(\"finished: writing out raw_df\")\n",
    "    \n",
    "    # clean_df -- all data from all providers (as dataframe)\n",
    "    # drop_duplicates -- dropping duplicated rows\n",
    "    clean_df = raw_df[list(col_names_dict_filter.keys())]\n",
    "    clean_df = clean_df.rename(columns= col_names_dict_filter)\n",
    "    \n",
    "    clean_df['State'] = 'PA'\n",
    "    clean_df = clean_df.drop_duplicates()\n",
    "    \n",
    "    # log number of duplicated rows dropped\n",
    "    count_duplicate = len(raw_df)-len(clean_df)\n",
    "    logging.info('number of duplicate rows removed =' + str(count_duplicate))\n",
    "    \n",
    "    clean_df.to_csv(clean_df_out_path, index=False)\n",
    "    \n",
    "    logging.info(\"finished: writing out clean_df\")\n",
    "        \n",
    "def main(): \n",
    "    ''' run get_provider_results for all providers\n",
    "\n",
    "    '''\n",
    "    provider_total_dict = dict()\n",
    "    provider_total_checks = dict()\n",
    "    \n",
    "    # prov_all -- all possible providers\n",
    "    prov_all = get_provider_list(DRIVER_PATH, URL)\n",
    "    # provider_texts -- list of providers we want to scrape\n",
    "    provider_texts = select_providers(providers_want, prov_all)\n",
    "    \n",
    "    #lopp through provider text\n",
    "    for provider_text in provider_texts:\n",
    "        logging.info('start data scraped for ' + str(provider_text))\n",
    "        \n",
    "        driver = nav_provider(provider_text, DRIVER_PATH, URL)\n",
    "        provider_results = get_provider_results(provider_text, driver)\n",
    "        driver.quit()\n",
    "        \n",
    "        # add results to provider_totals\n",
    "        provider_total_dict[provider_text] = provider_results[0]        \n",
    "        provider_total_checks[provider_text] = provider_results[1]\n",
    "    \n",
    "    # convert row_total to data frame log provider_total_checks\n",
    "    provider_total_checks = pd.DataFrame(provider_total_checks.values())\n",
    "    logging.info('Summary of provider_total_checks \\n\\t' \n",
    "                 + provider_total_checks.to_string().replace('\\n', '\\n\\t'))\n",
    "\n",
    "    \n",
    "    # write out data\n",
    "    write_out_data(provider_total_dict, DICT_OUT_PATH, RAW_DF_OUT_PATH, CLEAN_DF_OUT_PATH)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_spec_nlp",
   "language": "python",
   "name": "ds_spec_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
